{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Growth Charts\n",
    "\n",
    "Work to show the possible examples.\n",
    "\n",
    "Two main dictionaries are created:\n",
    "\n",
    "1. DDStats, indexed as a function of calendar day\n",
    "2. GStats, indexed as a function of team games played\n",
    "\n",
    "For the future, apply the boolean mask to make\n",
    "3. BStats, indexed as a function of potential games played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# give python3 compatibility\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# boilerplate imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "import datetime\n",
    "\n",
    "# imports for scraping\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.foxsports.com/mlb/transactions?year=2017&month=5&type=76\n",
      "2\n",
      "http://www.foxsports.com/mlb/transactions?year=2017&month=5&type=76\n",
      "Next ▸\n",
      "http://www.foxsports.com/mlb/transactions?year=2017&month=6&type=76\n",
      "2\n",
      "http://www.foxsports.com/mlb/transactions?year=2017&month=6&type=76\n",
      "3\n",
      "http://www.foxsports.com/mlb/transactions?year=2017&month=6&type=76\n",
      "Next ▸\n",
      "http://www.foxsports.com/mlb/transactions?year=2017&month=7&type=76\n",
      "2\n",
      "http://www.foxsports.com/mlb/transactions?year=2017&month=7&type=76\n",
      "Next ▸\n",
      "http://www.foxsports.com/mlb/transactions?year=2017&month=8&type=76\n",
      "2\n",
      "http://www.foxsports.com/mlb/transactions?year=2017&month=8&type=76\n",
      "3\n",
      "http://www.foxsports.com/mlb/transactions?year=2017&month=8&type=76\n",
      "Next ▸\n",
      "[u'Braves', u'ATL', u'Rodr\\xedguez, Sean', u'Rodr\\xedguez, S.', u'Placed on 60-Day DL - (Recovery from left shoulder surgery)', u'2/25', 30, 2]\n",
      "[u'Dodgers', u'LAD', u'Garc\\xeda, Yimi', u'Garc\\xeda, Y.', u'Placed on 60-Day DL - (Right elbow surgery - out for season)', u'2/15', 30, 2]\n",
      "[u'Rangers', u'TEX', u'Gonz\\xe1lez, Chi Chi', u'Gonz\\xe1lez, C.', u'Placed on 60-Day DL - (Right elbow surgery - out for season)', u'4/2', 30, 4]\n",
      "[u'Padres', u'SD', u'S\\xe1nchez, H\\xe9ctor', u'S\\xe1nchez, H.', u'Placed on 7-Day DL - (Concussion)', u'4/7', 65, 4]\n",
      "[u'Rangers', u'TEX', u'\\xc1lvarez, Dar\\xedo', u'\\xc1lvarez, D.', u'Placed on 10-Day DL - (Strained left elbow)', u'5/28', 76, 5]\n",
      "[u'Dodgers', u'LAD', u'Avil\\xe1n, Luis', u'Avil\\xe1n, L.', u'Placed on 10-Day DL - (Sore left triceps)', u'5/25', 76, 5]\n",
      "[u'Rockies', u'COL', u'Gonz\\xe1lez, Carlos', u'Gonz\\xe1lez, C.', u'Placed on 10-Day DL - (Strained right shoulder)', u'6/26', 76, 6]\n",
      "[u'Rangers', u'TEX', u'P\\xe9rez, Mart\\xedn', u'P\\xe9rez, M.', u'Placed on 10-Day DL - (Fractured right thumb)', u'6/24', 76, 6]\n",
      "[u'Giants', u'SF', u'N\\xfa\\xf1ez, Eduardo', u'N\\xfa\\xf1ez, E.', u'Placed on 10-Day DL - (Strained hamstring)', u'6/23', 76, 6]\n",
      "[u'White Sox', u'CHW', u'Garc\\xeda, Leury', u'Garc\\xeda, L.', u'Placed on 10-Day DL - (Sprained left finger)', u'6/19', 76, 6]\n",
      "[u'White Sox', u'CHW', u'Garc\\xeda, Avisa\\xedl', u'Garc\\xeda, A.', u'Placed on 10-Day DL - (Sprained right thumb)', u'7/27', 76, 7]\n",
      "[u'White Sox', u'CHW', u'Garc\\xeda, Willy', u'Garc\\xeda, W.', u'Placed on 7-Day DL - (Concussion)', u'8/1', 65, 8]\n",
      "[u'Mets', u'NYM', u'C\\xe9spedes, Yoenis', u'C\\xe9spedes, Y.', u'Placed on 10-Day DL - (Right hamstring strain)', u'8/26', 76, 8]\n",
      "[u'Twins', u'MIN', u'San\\xf3, Miguel', u'San\\xf3, M.', u'Placed on 10-Day DL - (Left shin stress reaction)', u'8/21', 76, 8]\n",
      "[u'Angels', u'LAA', u'Ram\\xedrez, J.C.', u'Ram\\xedrez, J.', u'Placed on 10-Day DL - (Right forearm strain)', u'8/21', 76, 8]\n",
      "[u'Rangers', u'TEX', u'G\\xf3mez, Carlos', u'G\\xf3mez, C.', u'Placed on 10-Day DL - (Right shoulder cyst)', u'8/19', 76, 8]\n",
      "[u'White Sox', u'CHW', u'L\\xf3pez, Reynaldo', u'L\\xf3pez, R.', u'Placed on 10-Day DL - (Strained back)', u'8/19', 76, 8]\n",
      "[u'Rockies', u'COL', u'D\\xedaz, Jairo', u'D\\xedaz, J.', u'Placed on 60-Day DL - (Right elbow inflammation)', u'9/10', 30, 9]\n",
      "[u'White Sox', u'CHW', u'Rod\\xf3n, Carlos', u'Rod\\xf3n, C.', u'Placed on 10-Day DL - (Left shoulder inflammation)', u'9/8', 76, 9]\n",
      "[u'Phillies', u'PHI', u'Florim\\xf3n, Pedro', u'Florim\\xf3n, P.', u'Placed on 10-Day DL - (Right ankle sprain)', u'9/5', 76, 9]\n",
      "[u'Rangers', u'TEX', u'B\\xe9ltre, Adri\\xe1n', u'B\\xe9ltre, A.', u'Placed on 10-Day DL - (Strained left hamstring)', u'9/3', 76, 9]\n",
      "[u'White Sox', u'CHW', u'Garc\\xeda, Leury', u'Garc\\xeda, L.', u'Placed on 10-Day DL - (Sprained right thumb)', u'9/2', 76, 9]\n",
      "http://www.foxsports.com/mlb/transactions?year=2017&month=5&type=76\n",
      "2\n",
      "http://www.foxsports.com/mlb/transactions?year=2017&month=5&type=76\n",
      "Next ▸\n",
      "http://www.foxsports.com/mlb/transactions?year=2017&month=6&type=76\n",
      "2\n",
      "http://www.foxsports.com/mlb/transactions?year=2017&month=6&type=76\n",
      "3\n",
      "http://www.foxsports.com/mlb/transactions?year=2017&month=6&type=76\n",
      "Next ▸\n",
      "http://www.foxsports.com/mlb/transactions?year=2017&month=7&type=76\n",
      "2\n",
      "http://www.foxsports.com/mlb/transactions?year=2017&month=7&type=76\n",
      "Next ▸\n",
      "http://www.foxsports.com/mlb/transactions?year=2017&month=8&type=76\n",
      "2\n",
      "http://www.foxsports.com/mlb/transactions?year=2017&month=8&type=76\n",
      "3\n",
      "http://www.foxsports.com/mlb/transactions?year=2017&month=8&type=76\n",
      "Next ▸\n",
      "[u'Braves', u'ATL', u'Rodr\\xedguez, Sean', u'Rodr\\xedguez, S.', u'Placed on 60-Day DL - (Recovery from left shoulder surgery)', u'2/25', 30, 2]\n",
      "[u'Dodgers', u'LAD', u'Garc\\xeda, Yimi', u'Garc\\xeda, Y.', u'Placed on 60-Day DL - (Right elbow surgery - out for season)', u'2/15', 30, 2]\n",
      "[u'Rangers', u'TEX', u'Gonz\\xe1lez, Chi Chi', u'Gonz\\xe1lez, C.', u'Placed on 60-Day DL - (Right elbow surgery - out for season)', u'4/2', 30, 4]\n",
      "[u'Padres', u'SD', u'S\\xe1nchez, H\\xe9ctor', u'S\\xe1nchez, H.', u'Placed on 7-Day DL - (Concussion)', u'4/7', 65, 4]\n",
      "[u'Rangers', u'TEX', u'\\xc1lvarez, Dar\\xedo', u'\\xc1lvarez, D.', u'Placed on 10-Day DL - (Strained left elbow)', u'5/28', 76, 5]\n",
      "[u'Dodgers', u'LAD', u'Avil\\xe1n, Luis', u'Avil\\xe1n, L.', u'Placed on 10-Day DL - (Sore left triceps)', u'5/25', 76, 5]\n",
      "[u'Rockies', u'COL', u'Gonz\\xe1lez, Carlos', u'Gonz\\xe1lez, C.', u'Placed on 10-Day DL - (Strained right shoulder)', u'6/26', 76, 6]\n",
      "[u'Rangers', u'TEX', u'P\\xe9rez, Mart\\xedn', u'P\\xe9rez, M.', u'Placed on 10-Day DL - (Fractured right thumb)', u'6/24', 76, 6]\n",
      "[u'Giants', u'SF', u'N\\xfa\\xf1ez, Eduardo', u'N\\xfa\\xf1ez, E.', u'Placed on 10-Day DL - (Strained hamstring)', u'6/23', 76, 6]\n",
      "[u'White Sox', u'CHW', u'Garc\\xeda, Leury', u'Garc\\xeda, L.', u'Placed on 10-Day DL - (Sprained left finger)', u'6/19', 76, 6]\n",
      "[u'White Sox', u'CHW', u'Garc\\xeda, Avisa\\xedl', u'Garc\\xeda, A.', u'Placed on 10-Day DL - (Sprained right thumb)', u'7/27', 76, 7]\n",
      "[u'White Sox', u'CHW', u'Garc\\xeda, Willy', u'Garc\\xeda, W.', u'Placed on 7-Day DL - (Concussion)', u'8/1', 65, 8]\n",
      "[u'Mets', u'NYM', u'C\\xe9spedes, Yoenis', u'C\\xe9spedes, Y.', u'Placed on 10-Day DL - (Right hamstring strain)', u'8/26', 76, 8]\n",
      "[u'Twins', u'MIN', u'San\\xf3, Miguel', u'San\\xf3, M.', u'Placed on 10-Day DL - (Left shin stress reaction)', u'8/21', 76, 8]\n",
      "[u'Angels', u'LAA', u'Ram\\xedrez, J.C.', u'Ram\\xedrez, J.', u'Placed on 10-Day DL - (Right forearm strain)', u'8/21', 76, 8]\n",
      "[u'Rangers', u'TEX', u'G\\xf3mez, Carlos', u'G\\xf3mez, C.', u'Placed on 10-Day DL - (Right shoulder cyst)', u'8/19', 76, 8]\n",
      "[u'White Sox', u'CHW', u'L\\xf3pez, Reynaldo', u'L\\xf3pez, R.', u'Placed on 10-Day DL - (Strained back)', u'8/19', 76, 8]\n",
      "[u'Rockies', u'COL', u'D\\xedaz, Jairo', u'D\\xedaz, J.', u'Placed on 60-Day DL - (Right elbow inflammation)', u'9/10', 30, 9]\n",
      "[u'White Sox', u'CHW', u'Rod\\xf3n, Carlos', u'Rod\\xf3n, C.', u'Placed on 10-Day DL - (Left shoulder inflammation)', u'9/8', 76, 9]\n",
      "[u'Phillies', u'PHI', u'Florim\\xf3n, Pedro', u'Florim\\xf3n, P.', u'Placed on 10-Day DL - (Right ankle sprain)', u'9/5', 76, 9]\n",
      "[u'Rangers', u'TEX', u'B\\xe9ltre, Adri\\xe1n', u'B\\xe9ltre, A.', u'Placed on 10-Day DL - (Strained left hamstring)', u'9/3', 76, 9]\n",
      "[u'White Sox', u'CHW', u'Garc\\xeda, Leury', u'Garc\\xeda, L.', u'Placed on 10-Day DL - (Sprained right thumb)', u'9/2', 76, 9]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url      =   \"http://www.foxsports.com/mlb/transactions?year={0}&month={1}&type={2}\"\n",
    "months = range(0,12)\n",
    "dl_down_types = [25, #15\n",
    "            30, #60\n",
    "            65, # 7\n",
    "            76] # 10\n",
    "dl_up_types = [35, #15\n",
    "            37, #60\n",
    "            67, # 7\n",
    "            77] # 10\n",
    "\n",
    "def Grab_Transaction_Data(in_year, month_list, in_transation_list):\n",
    "    rows = []\n",
    "    for month in month_list:\n",
    "        for dl in dl_down_types:\n",
    "            year_url = url.format(str(in_year), str(month), str(dl))\n",
    "            r               = requests.get(year_url)\n",
    "            soup            = BeautifulSoup(r.content)\n",
    "            paginatory      = soup.find(\"div\", { \"class\" : \"wisbb_paginator\"}) \n",
    "            if paginatory != None:\n",
    "                for anchor in paginatory.findAll('a'):\n",
    "                    print(year_url)\n",
    "                    print(anchor.text)\n",
    "            table_data      = soup.find(\"table\", { \"class\" : \"wisbb_standardTable wisbb_altRowColors\"})   \n",
    "            if table_data == None:\n",
    "                pass\n",
    "            else: \n",
    "                headers = [header.text for header in table_data.findAll('th')]\n",
    "                for row in table_data.findAll(\"tr\"):\n",
    "                    cells = row.findAll(\"td\")\n",
    "                    if len(cells) == 4:\n",
    "                        new_row = []\n",
    "                        for anchor in cells[0].findAll('a'):\n",
    "                             new_row.append(anchor.text)\n",
    "                        for anchor in cells[1].findAll('a'):\n",
    "                             new_row.append(anchor.text)\n",
    "                        for i in cells[2:]:\n",
    "                            new_row.append(i.find(text=True))\n",
    "                        new_row.append(dl)\n",
    "                        new_row.append(month)\n",
    "                        rows.append(new_row)\n",
    "    strip_rows = []\n",
    "    for row in rows:\n",
    "        try:\n",
    "            strip_rows.append([str(row[1]),\\\n",
    "                           str(row[3]),\\\n",
    "                           str(row[4]),\\\n",
    "                           str(row[5]),\\\n",
    "                           row[6],\\\n",
    "                           row[7]])\n",
    "        except:\n",
    "            print(row)\n",
    "    headers.append(\"DL Code\")\n",
    "    headers.append(\"Month\")\n",
    "    df = pd.DataFrame(strip_rows, columns=headers)\n",
    "    df['Date Time'] = pd.to_datetime(df['Date']+\"/{0}\".format(in_year))\n",
    "    return df\n",
    "\n",
    "up_transactions = Grab_Transaction_Data('2017', months[:11], dl_up_types)\n",
    "down_transactions = Grab_Transaction_Data('2017', months[:11], dl_down_types)\n",
    "unique_names = down_transactions.groupby(\"Player\")['Player'].first()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(up_transactions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Grab 2017 Down Data\n",
    "rows = []\n",
    "for month in months:\n",
    "    for dl in dl_down_types:\n",
    "        year_url = url.format(str(2016), str(month), str(dl))\n",
    "#        year_url = url.format(str(2017), str(4), str(0))\n",
    "        r               = requests.get(year_url)\n",
    "        soup            = BeautifulSoup(r.content)\n",
    "#        text_file = open(\"Output2.txt\", \"w\")\n",
    "#        text_file.write(str(soup))\n",
    "#        text_file.close()\n",
    "        paginatory      = soup.find(\"div\", { \"class\" : \"wisbb_paginator\"}) \n",
    "        if paginatory != None:\n",
    "            for anchor in paginatory.findAll('a'):\n",
    "                print year_url\n",
    "                print anchor.text\n",
    "        table_data      = soup.find(\"table\", { \"class\" : \"wisbb_standardTable wisbb_altRowColors\"})   \n",
    "        if table_data == None:\n",
    "            pass\n",
    "        else: \n",
    "            headers = [header.text for header in table_data.findAll('th')]\n",
    "            # All of our data is in a 'Beautiful Soup' but we think in tables so let's coerce this data into a shape\n",
    "            for row in table_data.findAll(\"tr\"):\n",
    "                cells = row.findAll(\"td\")\n",
    "                if len(cells) == 4:\n",
    "                    new_row = []\n",
    "                    for anchor in cells[0].findAll('a'):\n",
    "                         new_row.append(anchor.text)\n",
    "                    for anchor in cells[1].findAll('a'):\n",
    "                         new_row.append(anchor.text)\n",
    "                    for i in cells[2:]:\n",
    "                        new_row.append(i.find(text=True))\n",
    "                    new_row.append(dl)\n",
    "                    new_row.append(month)\n",
    "                    rows.append(new_row)\n",
    "\n",
    "# Damn that was a shit way to do things. Strip out the unnecessary stuff.\n",
    "strip_rows = []\n",
    "for row in rows:\n",
    "    strip_rows.append([str(row[1]),\n",
    "                       str(row[3]),\n",
    "                       str(row[4]),\n",
    "                       str(row[5]),\n",
    "                       row[6],\n",
    "                       row[7]])\n",
    "\n",
    "## Great, our Data is in a list of lists: much more pythonic. Let's birth a pandas table!\n",
    "headers.append(\"DL Code\")\n",
    "headers.append(\"Month\")\n",
    "df16 = pd.DataFrame(strip_rows, columns=headers)\n",
    "df16['Date Time'] = pd.to_datetime(df16['Date']+\"/2016\")\n",
    "\n",
    "rows = []\n",
    "for month in months[:10]:\n",
    "    for dl in dl_types:\n",
    "        year_url = url.format(str(2017), str(month), str(dl))\n",
    "#        year_url = url.format(str(2017), str(4), str(0))\n",
    "        r               = requests.get(year_url)\n",
    "        soup            = BeautifulSoup(r.content)\n",
    "#        text_file = open(\"Output2.txt\", \"w\")\n",
    "#        text_file.write(str(soup))\n",
    "#        text_file.close()\n",
    "        paginatory      = soup.find(\"div\", { \"class\" : \"wisbb_paginator\"}) \n",
    "        if paginatory != None:\n",
    "            for anchor in paginatory.findAll('a'):\n",
    "                print(year_url)\n",
    "                print(anchor.text)\n",
    "        table_data      = soup.find(\"table\", { \"class\" : \"wisbb_standardTable wisbb_altRowColors\"})   \n",
    "        if table_data == None:\n",
    "            pass\n",
    "        else: \n",
    "#            headers = [header.text for header in table_data.findAll('th')]\n",
    "            # All of our data is in a 'Beautiful Soup' but we think in tables so let's coerce this data into a shape\n",
    "            for row in table_data.findAll(\"tr\"):\n",
    "                cells = row.findAll(\"td\")\n",
    "                if len(cells) == 4:\n",
    "                    new_row = []\n",
    "                    for anchor in cells[0].findAll('a'):\n",
    "                         new_row.append(anchor.text)\n",
    "                    for anchor in cells[1].findAll('a'):\n",
    "                         new_row.append(anchor.text)\n",
    "                    for i in cells[2:]:\n",
    "                        new_row.append(i.find(text=True))\n",
    "                    new_row.append(dl)\n",
    "                    new_row.append(month)\n",
    "                    rows.append(new_row)\n",
    "\n",
    "# Damn that was a shit way to do things. Strip out the unnecessary stuff.\n",
    "strip_rows = []\n",
    "for row in rows:\n",
    "    strip_rows.append([str(row[1]),\n",
    "                       str(row[3]),\n",
    "                       str(row[4]),\n",
    "                       str(row[5]),\n",
    "                       row[6],\n",
    "                       row[7]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reorganize with game numbers(e.g. including days the team played and they sat)\n",
    "\n",
    "zero_day = 75\n",
    "max_day = 300\n",
    "buff = 50\n",
    "\n",
    "GStats = {}\n",
    "\n",
    "# loop for each stat\n",
    "for key1 in np.array(DDStats.keys()):\n",
    "    \n",
    "    GStats[key1] = {}\n",
    "    \n",
    "    # loop for each player\n",
    "    for key2 in np.array(DDStats[key1].keys()):\n",
    "        \n",
    "        # initialize arrays (strings for team names and positions)\n",
    "        if key1 in ['OPP','POS','TEAM']:\n",
    "            GStats[key1][key2] = np.zeros(max_day-zero_day+buff,dtype='S5')\n",
    "            \n",
    "        # zeros for everything else\n",
    "        else:\n",
    "            GStats[key1][key2] = np.zeros(max_day-zero_day+buff) + np.nan\n",
    "            \n",
    "        # step through each calendar day\n",
    "        gnum = 0 # log of each game number\n",
    "        for indx,val in enumerate(DDStats[key1][key2]):\n",
    "            \n",
    "            # in this loop, indx is the number of days from march 16th\n",
    "                        \n",
    "            # step 1: did the player have plate appearances on a given day?\n",
    "            if DDStats['POS'][key2][indx] != '':\n",
    "                GStats[key1][key2][gnum] = DDStats[key1][key2][indx]\n",
    "                gnum += 1\n",
    "                \n",
    "            # step 2: were they on the DL?\n",
    "            \n",
    "            #\n",
    "            # here is where the boolean mask gets plugged in\n",
    "            #\n",
    "                \n",
    "            # step 3: if neither of above, did their team play?\n",
    "            else:\n",
    "                # identify which team player is on (forward-looking)\n",
    "                indx1 = 0\n",
    "                while (DDStats['TEAM'][key2][indx+indx1] == '') & (indx1 < 3) & (indx < 210):\n",
    "                    indx1 += 1\n",
    "\n",
    "                # once out of loop, identify which team\n",
    "                which_team = DDStats['TEAM'][key2][indx+indx1]\n",
    "                \n",
    "                # check if team had a game: if yes, advance one day\n",
    "                if which_team != '':\n",
    "                    if (indx+zero_day) in GGDict[translate_team(team_translate,which_team)]:\n",
    "                        #print('off day')\n",
    "                        GStats[key1][key2][gnum] = 0.#GStats[key1][key2][gnum-1]\n",
    "                        gnum += 1\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Questions\n",
    "\n",
    "1. How to treat DL?\n",
    "2. How to treat off days?\n",
    "\n",
    "### Desired Functionality\n",
    "\n",
    "1. By batting order\n",
    "2. By position\n",
    "3. By age\n",
    "4. By opponent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Example 1: RBI across the league (no PA cuts), with Whit imposed\n",
    "#\n",
    "\n",
    "PAlist = np.zeros([len(np.array(DDStats['PA'].keys())),max_day-zero_day])\n",
    "\n",
    "\n",
    "stat = 'RBI'\n",
    "print(len(np.array(DDStats[stat].keys())) )\n",
    "\n",
    "for indx,player in enumerate(DDStats[stat].keys()):\n",
    "    PAlist[indx] = np.cumsum(DDStats[stat][player])\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0.18,0.22,0.6,0.7])\n",
    "ax2 = fig.add_axes([0.81,0.22,0.02,0.7])\n",
    "\n",
    "    \n",
    "    \n",
    "for perc in range(100,0,-10):\n",
    "    ax.plot(np.percentile(PAlist,perc,axis=0),color=cm.gnuplot(float(perc/100.),1.))\n",
    "    \n",
    "\n",
    "ax.plot(np.cumsum(DDStats[stat]['Whit Merrifield']),color='black')\n",
    "\n",
    "    \n",
    "ax.set_ylabel('RBIs',size=18)\n",
    "ax.set_xlabel('Gameday Number',size=18)\n",
    "    \n",
    "cmap = mpl.cm.gnuplot; norm = mpl.colors.Normalize(vmin=0, vmax=100)\n",
    "cb1 = mpl.colorbar.ColorbarBase(ax2, cmap=cmap,norm=norm)\n",
    "cb1.set_label('Percentile',size=18)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Example 2: runs for second basemen who started >50 games, sorted by game numbers\n",
    "#    with Jose Altuve plotted over the top\n",
    "\n",
    "buff = 50\n",
    "des_pos = '2B'\n",
    "\n",
    "\n",
    "plist = []\n",
    "\n",
    "for indx,plr in enumerate(DDStats['POS'].keys()):\n",
    "    if len(np.where(GStats['POS'][plr] == des_pos)[0]) > 50:\n",
    "        plist.append(plr)\n",
    "        \n",
    "\n",
    "PAlist = np.zeros([len(plist),max_day-zero_day+buff])\n",
    "\n",
    "\n",
    "\n",
    "stat = 'R'\n",
    "#print(len(np.array(DDStats[stat].keys())) )\n",
    "\n",
    "#for indx,player in enumerate(DDStats[stat].keys()):\n",
    "for indx,player in enumerate(np.array(plist)):\n",
    "    \n",
    "    PAlist[indx] = np.cumsum(GStats[stat][player])\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0.18,0.22,0.6,0.7])\n",
    "ax2 = fig.add_axes([0.81,0.22,0.02,0.7])\n",
    "\n",
    "    \n",
    "    \n",
    "for perc in range(100,0,-10):\n",
    "    ax.plot(np.nanpercentile(PAlist,perc,axis=0),color=cm.gnuplot(float(perc/100.),1.))\n",
    "    \n",
    "\n",
    "ax.plot(np.cumsum(GStats[stat]['Jose Altuve']),color='black')\n",
    "\n",
    "\n",
    "    \n",
    "ax.set_ylabel(stat,size=18)\n",
    "ax.set_xlabel('GAME Number',size=18)\n",
    "    \n",
    "cmap = mpl.cm.gnuplot; norm = mpl.colors.Normalize(vmin=0, vmax=100)\n",
    "cb1 = mpl.colorbar.ColorbarBase(ax2, cmap=cmap,norm=norm)\n",
    "cb1.set_label('Percentile',size=18)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Example 3: several positions, plotting R\n",
    "#\n",
    "fig = plt.figure(figsize=(6,2))\n",
    "\n",
    "for indx1,des_pos in enumerate(np.array(['C','1B','2B','3B','SS','CF','RF','LF'])):\n",
    "    \n",
    "    ax = fig.add_axes([0.12+(indx1*(0.75-.12)/7.),0.22,(0.75-.12)/7.,0.7])\n",
    "\n",
    "\n",
    "    plist = []\n",
    "\n",
    "    for indx,plr in enumerate(GStats['POS'].keys()):\n",
    "        \n",
    "        try:\n",
    "            if len(np.where(GStats['POS'][plr] == des_pos)[0]) > 50:\n",
    "                plist.append(plr)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "    PAlist = np.zeros([len(plist),max_day-zero_day+buff])\n",
    "\n",
    "\n",
    "    stat = 'R'\n",
    "\n",
    "    for indx,player in enumerate(np.array(plist)):\n",
    "\n",
    "        PAlist[indx] = np.nancumsum(GStats[stat][player])\n",
    "\n",
    "\n",
    "    for perc in range(100,0,-10):\n",
    "        ax.plot(np.percentile(PAlist,perc,axis=0),color=cm.gnuplot(float(perc/100.),1.))\n",
    "\n",
    "\n",
    "    if indx1==0: \n",
    "        ax.set_ylabel(stat,size=18)\n",
    "    else:\n",
    "        ax.set_yticklabels(())\n",
    "        \n",
    "    if indx1==3: ax.set_xlabel('Game Number',size=18)\n",
    "    ax.set_title(des_pos,size=18)\n",
    "\n",
    "    ax.axis([0.0,162.,0.,140.])\n",
    "    \n",
    "\n",
    "ax2 = fig.add_axes([0.90,0.22,0.01,0.7])\n",
    "\n",
    "\n",
    "cmap = mpl.cm.gnuplot; norm = mpl.colors.Normalize(vmin=0, vmax=100)\n",
    "cb1 = mpl.colorbar.ColorbarBase(ax2, cmap=cmap,norm=norm)\n",
    "cb1.set_label('Percentile',size=18)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
